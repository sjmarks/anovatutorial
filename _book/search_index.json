[
["index.html", "1-Way ANOVA- Model Representations, Power, and Sample Size Tutorial Part 1 Introduction", " 1-Way ANOVA- Model Representations, Power, and Sample Size Tutorial Simon Marks 2020-06-12 Part 1 Introduction ANOVA is short for analysis of variance. It is a widely used statistical method used with designed experiments. Given its frequency of use, it is my opinion that anyone interested in academic research understand the basics. . . even if you never use it in your own research, I guarantee you will encounter it somewhere in the literature! Briefly, ANOVA is an “accounting” procedure that keeps track of all the variation in a response variable. ANOVA partitions this variation into pieces and uses these pieces to assess the likelihood that differences found between means in sample data could be the result of random chance. This tutorial focuses on 1-way ANOVA, specifically ways to model our data in the context of this statistical method. We introduce the means and effects models and their assumptions and implement these approaches manually in R. We also discuss power and sample size and provide an interactive visualization to see what influences power in an ANOVA. Discussion of power and sample size helps answer the question: “How might we increase the chances of getting a statistically significant result from our ANOVA?” Thinking about power and sample size not only will bolster your statistical chops, it might also come in handy in practice when planning research design or writing research grant proposals. The tutorial assumes you have used R before and are familar working with matrices. Some examples and demos utilize functions from the Tidyverse (Wickham 2019). This tutorial was written using the bookdown package (Xie 2020), which was built on top of R Markdown and knitr (Xie 2015). References "],
["basics.html", "Part 2 ANOVA Basics 2.1 Check-in", " Part 2 ANOVA Basics As alluded to in Part 1 of this tutorial, we use ANOVA to make decisions about the relationships among means. Typically we do this when we have more than two treatment groups. This is because we could simply use a two-sample t-test to compare two (independent) groups. The power of ANOVA is that we can compare more than two means. For example, let us look at the InsectSprays data set in R (Beall 1942). This simple data set provides counts of insects treated with 6 different insecticides. First, let us consider the components of this experiment and its design: Treatment Structure Factor: Insecticide (spray) Level: 6 levels (A, B, C, D, E, F) Design Structure Experimental Unit: A plot of insects Randomization Method: Completely randomized design (CRD) Replication: 12 replicates per type of insecticide (spray) Response Variable Number of insects counted in a plot after application of insecticide The design structure above warrants some additional discussion. Firstly, the experimental unit is defined as the unit that the treatment is applied. The randomization method of CRD communicates that the experimental units were randomly assigned to each treatment. In this case, insect plots were randomly assigned one of the 6 sprays. Random assignment equalizes the extraneous sources of variability in comparison of the treatment groups. This enables cause and effect conclusions to be drawn from the experiment, protecting against extra variation in the response variable from becoming confounding variables. For example, we might assume that the insects in this study have genetic variation which would make some insects more or less susceptible to certain sprays- CRD makes sure this isn’t the reason a plot responds a certain way to one of the 6 sprays. Lastly, replication is important because it serves to distribute extraneous variation in the response equally, giving us a reasonably equal variance within all treatment groups. With the preliminaries out of the way, let us now explore the InsectSprays data: insects &lt;- InsectSprays insects %&gt;% group_by(spray) %&gt;% summarise(mean = mean(count), `std dev` = sd(count)) ## # A tibble: 6 x 3 ## spray mean `std dev` ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 A 14.5 4.72 ## 2 B 15.3 4.27 ## 3 C 2.08 1.98 ## 4 D 4.92 2.50 ## 5 E 3.5 1.73 ## 6 F 16.7 6.21 Figure 2.1: Boxplot showing differences and variation in count response between insecticide treatment groups. Looking at the produced tibble and box plot, it appears that there is variability in insect count for insect plots exposed to different insecticides. Insect plots exposed to Spray F had the highest count on average (16.7), while insect plots exposed to Spray C had the lowest count on average (2.08). The graph and table also illustrate differences in within treatment group variation for the 6 sprays; the spread of the observations vary between each group. For example, the Spray E group had low variance with a standard deviation of 1.73 insects, while Spray F had high variance with a standard deviation of 6.21 insects. These initial observations from our data exploration are nice, but the question remains as to whether or not the observed variation in the insect counts is truly due to variation due to spray. The next part of the tutorial will demonstrate two models for our data that will help us answer this question. 2.1 Check-in Suppose the insect plots in the above experiment were comprised using only one insect species. What is one statistical advantage of doing this? What is the statistical disadvantage of limiting plots to one type of insect species? References "],
["meanseffects.html", "Part 3 The Means and Effects Models 3.1 ANOVA Bookkeeping 3.2 Means Model 3.3 Effects Model 3.4 Check-in", " Part 3 The Means and Effects Models 3.1 ANOVA Bookkeeping In Part 1 we mentioned ANOVA is a way to keep track of the variation in a response variable. Figure 3.1 provides a schematic for how we can think about this for our InsectSprays data set example introduced in Part 2. Figure 3.1: Conceptual diagram for variation accounting in the insecticide example. In 1-way ANOVA we partition the total variation in our response variable (SS Total) into two parts- variation due to treatment (SS Treatment) and the random error left over (SS Error), viz (Kutner et al. 2005)., \\[SS_{total} = SS_{trt} + SS_{error} = \\sum_{i,j} (y_{ij} - \\overline{y}_{..})^2\\] \\[ SS_{trt} = \\sum_{i,j} (\\overline{y}_{i.} - \\overline{y}_{..})^2 \\] \\[ SS_{error} = \\sum_{i,j} (y_{ij} - \\overline{y}_{i.})^2 \\] Don’t be intimidated by the formulas above. Basically, all we are saying is that we can decompose the total deviation from the overall mean response into two components: The deviation of each treatment group mean from the grand mean of the response variable (between treatment group mean variation) The deviation of each observation from its treatment group mean (within treatment group variation) Figures 3.2, 3.3, and 3.4 provide visuals for each variation component in the context of our InsectSprays example. Figure 3.2: Visual of SS Total. The red-dotted line represents the grand mean insect count calculated from all insect plots. SS total is computed by subtracting each observed count from a plot from this grand mean, squaring, and then summing these values. Figure 3.3: Visual of SS Treatment. The red-dotted line once again represents the grand mean for insect count. SS Treatment is computed by subtracting each treatment group mean for insect count (color coded lines) from this grand mean, squaring, and then multiplying by the j replicates comprising each treatment group, in this case 12. The 6 values corresponding to each treatment group resulting from this computation are then summed. Figure 3.4: Visual of SS Error. The red-dotted line in each panel represents each treatment group mean for insect count. SS Error is computed by subtracting each observed count from a plot from its respective treatment group mean, squaring, and then summing these values. ANOVA compares the variability due to the treatment to that due to error to generate a test statistic. We will now see how we can compute these variance quantities and do ANOVA in R by applying a model to our data. 3.2 Means Model We can model our 1-way ANOVA data using the means model, an additive linear model for when our explanatory variable is categorical, viz., \\[y_{ij} = \\mu_{i} + \\epsilon_{ij} \\] where \\(y_{ij}\\) ~ independent and Normal (\\(\\mu_{i}, \\sigma^2\\)) and \\(\\epsilon_{ij}\\) ~ independent and Normal (\\(0, \\sigma^2\\)). Let’s define what the parameters in this expression represent in the context of our InsectSprays example: \\(y_{ij}\\) represents the insect count for the \\(jth\\) insect plot given the \\(ith\\) insecticide spray \\(\\mu_{i}\\) represents the true mean insect count for all insect plots given the \\(ith\\) insecticide spray \\(\\epsilon_{ij}\\) represents the error for the for the \\(jth\\) insect plot given the \\(ith\\) insecticide spray Note that the equation form of this model uses parameter notation (e.g. we are talking about a population). When we use this model in practice we estimate the parameters with statistics from our data. Without further ado, let’s do some computing! 3.2.1 Employing the Means Model to do 1-way ANOVA in R The below code uses the means model and matrix algebra to eventually compute the ANOVA F-statistic for our InsectSprays example. ### ANOVA Preliminaries## Datainsects ## response variable (n x 1 matrix)response_variable %&nbsp;&nbsp;pull(count) %>% &nbsp;&nbsp;as.matrix()## Design matrix (n x p matrix)# Each column is using indicator coding, a ‘1’ for the treatment, and 0 for other. So column 1 will generate the mean for treatment level1, column 2 for treatment level2, and column 3 for treatment level3 and so on.design_matrix ## p x 1 matrix of treatment meanstrt_means design_matrix), crossprod(design_matrix, response_variable))### ANOVAn p design_matrix)j ## Variation computationsss_tot ss_trt trt_means) %*% crossprod(design_matrix, response_variable)) - (1/n) * crossprod(response_variable, j) %*% response_variabless_error ss_tot - ss_trt## Degrees of freedomtotal_df trt_df error_df ## Compute F-statMS_trt ss_trt / trt_dfMS_error ss_error / error_dfF_stat A few points to note about the code above: The design matrix (often denoted X) is useful to estimate our \\(\\mu_{i}\\) parameters (treatment means) from the means model. The design matrix is a way to represent the number of treatment groups and replicates per treatment group. Our InsectSprays data is a little lengthy to show its full means model design matrix, so let’s simplify and say we only have only 6 insect plots with 3 different sprays (2 replicates per spray). We represent the design matrix (X) and compute the treatment means (\\(\\overline{y}_{i.}\\)), viz., \\[\\left[\\begin{array} {rrr} y_{1,1} \\\\ y_{1,2} \\\\ y_{2,1} \\\\ y_{2,2}\\\\ y_{3,1} \\\\ y_{3,2} \\\\ \\end{array}\\right] = \\left[\\begin{array} {rrr} 1 &amp; 0 &amp; 0 \\\\ 1 &amp; 0 &amp; 0\\\\ 0 &amp; 1 &amp; 0\\\\ 0 &amp; 1 &amp; 0\\\\ 0 &amp; 0 &amp; 1\\\\ 0 &amp; 0 &amp; 1\\\\ \\end{array}\\right] \\left[\\begin{array} {rrr} \\mu_{1} \\\\ \\mu_{2} \\\\ \\mu_{3} \\\\ \\end{array}\\right] + \\left[\\begin{array} {rrr} \\epsilon_{1,1} \\\\ \\epsilon_{1,2} \\\\ \\epsilon_{2,1} \\\\ \\epsilon_{2,2}\\\\ \\epsilon_{3,1} \\\\ \\epsilon_{3,2} \\\\ \\end{array}\\right]\\] \\[\\overline{y}_{i.} = (X&#39;X)^{-1}X&#39;Y\\] Our SS values are computed using matrix operations carrying out the equations described in 3.1. For brevity I will not describe the operations in detail. Lastly, our ANOVA F-statistic is calculated by taking the ratio of our mean sum of squares treatment (between treatment group variation) and mean sum of squares error (within treatment group variation). A high F-statistic is our measure to suggest the variation is largely explained by our explanatory variable rather than random variation. In the context of the means model, it allows us to conclude that at least one of our treatment means is significantly different from 0. The value of our F-statistic for our InsectSprays example computed above is: F_stat ## [,1] ## [1,] 34.70228 This is the same result as using R’s built in anova function test_ANOVA &lt;- lm(insects$count ~ insects$spray) anova(test_ANOVA) ## Analysis of Variance Table ## ## Response: insects$count ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## insects$spray 5 2668.8 533.77 34.702 &lt; 2.2e-16 *** ## Residuals 66 1015.2 15.38 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 3.3 Effects Model We can model our 1-way ANOVA data using another additive linear model for when our explanatory variable is categorical, called the effects model, viz., \\[y_{ij} = \\mu + \\tau_{i} + \\epsilon_{ij} \\] where \\(y_{ij}\\) ~ independent and Normal (\\(\\mu + \\tau_{i}, \\sigma^2\\)) and \\(\\epsilon_{ij}\\) ~ independent and Normal (\\(0, \\sigma^2\\)). Similar to what we did with the means model, lets define what the parameters of the effects model represent in the context of our InsectSprays example: \\(y_{ij}\\) represents the insect count for the \\(jth\\) insect plot given the \\(ith\\) insecticide spray \\(\\mu\\) represents the true mean insect count for all insect plots given a spray \\(\\tau_{i}\\) represents the effect of the the \\(ith\\) insecticide spray on insect count \\(\\epsilon_{ij}\\) represents the error for the for the \\(jth\\) insect plot given the \\(ith\\) insecticide spray An effect in the context of this model is the difference between the mean for the \\(ith\\) treatment and the grand mean. We operate under the constraint that all our estimated effects sum to 0, viz., \\[\\sum\\tau_{i} = 0\\] You will see the role of this assumption after we employ the effects model in R. 3.3.1 Employing the Effects Model to do 1-way ANOVA in R ### ANOVA Preliminaries## Datainsects ## response variable (n x 1 matrix)response_variable %&nbsp;&nbsp;pull(count) %>% &nbsp;&nbsp;as.matrix()## Design matrix (n x p matrix)# First column is now an intercept term used to compute the grand meancontrasts(insects$spray) design_matrix ## p x 1 matrix of effects model parametersmodel_param design_matrix), crossprod(design_matrix, response_variable))### ANOVAn p design_matrix)j ## Variation computationsss_tot ss_trt model_param) %*% crossprod(design_matrix, response_variable)) - (1/n) * crossprod(response_variable, j) %*% response_variabless_error ss_tot - ss_trt## Degrees of freedomtotal_df trt_df error_df ## Compute F-statMS_trt ss_trt / trt_dfMS_error ss_error / error_dfF_stat Our ANOVA computation is largely the same as what we did for the means model, but our design matrix this time around helps compute the parameters for the effects model, namely our grand mean and effects for our treatments. model_param ## [,1] ## (Intercept) 9.500000 ## insects$spray1 5.000000 ## insects$spray2 5.833333 ## insects$spray3 -7.416667 ## insects$spray4 -4.583333 ## insects$spray5 -6.000000 The intercept term here is our grand mean insect count- 9.5 insects. Using our effect estimations we can easily calculate means for the treatment groups: model_param %&gt;% as.data.frame() %&gt;% rename(param = V1) %&gt;% tibble::rownames_to_column() %&gt;% mutate(trt_mean = 9.5 + param) ## rowname param trt_mean ## 1 (Intercept) 9.500000 19.000000 ## 2 insects$spray1 5.000000 14.500000 ## 3 insects$spray2 5.833333 15.333333 ## 4 insects$spray3 -7.416667 2.083333 ## 5 insects$spray4 -4.583333 4.916667 ## 6 insects$spray5 -6.000000 3.500000 Notice that we are missing one effect estimate for spray F! This is because we must drop a treatment group from the model for the matrix operations to work (we sacrifice a treatment group effect to compute the grand mean). We can find the missing effect by recalling the model assumption \\(\\sum\\tau_{i} = 0\\). missing_effect &lt;- model_param %&gt;% as.data.frame() %&gt;% rename(param = V1) %&gt;% tibble::rownames_to_column() %&gt;% slice(2:6) sum(missing_effect$param) ## [1] -7.166667 Our missing effect for spray F is therefore 7.167 insects. Our F-statistic remains the same as what it was for the means model when computing with the effects model. It is again 34.7. The interpretation changes from what we said in the means model- it suggests that at least one of the effects of the \\(ith\\) insect spray on insect count are not equal to 0. 3.4 Check-in Suppose we ran our InsectSprays experiment twice using only sprays D, E, and F and obtained the following results: Scenario 1 ## # A tibble: 3 x 3 ## spray mean `std dev` ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 D 4.92 2.50 ## 2 E 3.5 1.73 ## 3 F 16.7 6.21 Scenario 2 ## # A tibble: 3 x 3 ## spray mean `std dev` ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 D 4.92 3.2 ## 2 E 3.5 2 ## 3 F 16.7 7. Assume in both scenarios that 12 replicates per treatment group were used. Will one of the two data sets produce a larger F-statistic (Scenario 1 or Scenario 2)? Why or why not. Suppose we want to run an ANOVA on a experiment set-up with 3 different treatment groups (2 replicates per treatment) using the effects model. There is 1 observation of the response variable per replicate for this experiment. To compute our model parameters, how would we set up the design matrix? References "],
["power-and-sample-size.html", "Part 4 Power and Sample Size 4.1 Power 4.2 Playing with Sample Size", " Part 4 Power and Sample Size The F-statistic we obtained from our insectSprays example was so large that we assumed it was a statistically significant result. Of course in practice we would conduct a formal hypothesis test and invoke a null F-distribution to test statistical significance. For our effects model we put together for insectSprays we would pose the following null and alternative hypotheses: \\(H_{0}\\): The type of spray has no effect on insect count in the population of all insect plots. \\(H_{a}\\): The type of spray has an effect on insect count in the population of all insect plots. We can plot the null F(5, 66) distribution in R: insects_F &lt;- ggplot(NULL, aes(x = c(0, 35))) + stat_function(fun = df, geom = &quot;area&quot;, fill = &quot;steelblue&quot;, args = list(df1 = 5, df2 = 66), alpha = 0.6) + theme_classic() + xlab(&quot;F&quot;) + ylab(&quot;Density&quot;) + stat_function(fun = df, args = list(df1 = 5, df2 = 66), geom = &quot;area&quot;, fill = &quot;steelblue&quot;, xlim = c(qf(p = 0.99, df1 = 5, df2 = 66), 35) ) + geom_vline(xintercept = qf(p = 0.99, df1 = 5, df2 = 66), color = &quot;red&quot;) + geom_vline(xintercept = 34.7, linetype = &quot;dashed&quot;) Figure 4.1: Null F-distribution with a numerator df = 5 and denominator df = 66. The dark blue shaded area demarcated by the solid red line represents the the critical F-statistic value at which to reject our null hypotheis at the 0.01 significance level. Our obtained F-statistic (black dashed line) clearly exceeds this threshold! F(5, 66) = 34.7 with p-value &lt;0.0001 I’d say we were pretty safe to assume what what we did in Part 3 (essentially we rejected the null hypothesis posed above) just from glancing at the size of our computed F-statistic. Our insectSprays example lended itself pretty darn well to getting a statistically significant F-statistic. A worthwhile question to ask if we were setting up our own experimental design outside of this example would be: How can we design our experiment to increase our chances of getting a statistically significant F-statistic? 4.1 Power The answer to the above question can be answered by thinking about power. Power is the probability that we reject our null hypothesis when in fact the null hypothesis is actually false (Oehlert 2010). To make sense of this recall the Type I error and Type II error rates from introductory statistics: Type I Error Rate: Probability that we reject our null hypothesis when it is in fact the null is true Type II Error Rate: Probabilility that we fail to reject the null hypothesis when in fact the null is false Power represents the probability of the “correct” decision between these two errors rates. To determine power in the context of 1-way ANOVA we can plot both the central (null) and non-central F-distributions. The central F-distribution (an example is 4.1) shows the distribution of F-statistics when our null hypothesis is actually true. On the other hand, the non-central F-distribution shows the distribution of F-statistics when the the null hypothesis is actually false. The shape of the non-central F-distribution is dictated by a non-centrality parameter, viz., \\[NCP = \\frac{\\sum n_{i}\\tau_{i}^2}{\\sigma^2}\\] We can estimate \\(\\tau_{i}^2\\) as the effect of the \\(ith\\) treatment group, \\(n_{i}\\) as the sample size (replicates) per treatment group, and \\(\\sigma^2\\) as mean square error (MSE). To illustrate how the central and non-central F-distributions are used to determine power, let us look at a situation where we modify our beloved insectSprays example. Suppose we wanted to determine power for an ANOVA F-test for a new insecticide study we were planning with the following assumptions: Our level of significance is \\(\\alpha = 0.05\\) We will have three treatment groups (3 sprays) with 10 insect plots per treatment Our MSE will be 2 insects We assume the true mean change in insect count for the treatments will be \\(\\mu_{1} = 4\\), \\(\\mu_{2} = 5\\), and \\(\\mu_{3} = 6\\) We plot our central and non-central F-distributions to calculate power for the ANOVA F-test (\\(H_{0}\\): \\(\\mu_{1}\\) = \\(\\mu_{2}\\) = \\(\\mu_{3}\\)). To plot the latter distribution we need to compute our non-centrality parameter: group_means &lt;- c(4, 5, 6) grand_mean &lt;- mean(group_means) ncp_1 &lt;- 10 * ((group_means[1] - grand_mean)^2 + (group_means[2] - grand_mean)^2 + (group_means[3] - grand_mean)^2)/2 ncp_1 ## [1] 10 Plotting our distributions: example_power_fdists &lt;- ggplot(NULL, aes(x = c(0, 15))) + # Null F-distribution F(2, 27, 0) stat_function(fun = df, geom = &quot;area&quot;, fill = &quot;steelblue&quot;, args = list(df1 = 2, df2 = 27, ncp = 0), alpha = 0.8) + # Non-central F-distribution F (2, 27, 10) stat_function(fun = df, geom = &quot;area&quot;, fill = &quot;yellow&quot;, args = list(df1 = 2, df2 = 27, ncp = ncp_1), alpha = 0.5) + # Power stat_function(fun = df, args = list(df1 = 2, df2 = 27, ncp = ncp_1), geom = &quot;area&quot;, fill = &quot;green&quot;, alpha = 0.5, xlim = c(qf(p = pf(qf(0.95, 2, 27), 2, 27, ncp = ncp_1, lower.tail = F), df1 = 2, df2 = 27, ncp = ncp_1, lower.tail = FALSE), 20)) + # F-critical value (alpha = 0.05) geom_vline(xintercept = qf(p = 0.95, df1 = 2, df2 = 27), color = &quot;red&quot;, linetype = &quot;dashed&quot;) + theme_classic() + ylab(&quot;Density&quot;) + xlab(&quot;F&quot;) Figure 4.2: Plotted F (2, 27, 0) and F(2, 27, 10) distributions (represented by the blue and yellow/green shadings respectively). The power of our ANOVA F-test is the shaded green area of the non-central F-distribution to the right of the red-dashed line. Our power is the green shaded area, the density of upper tail of the non-central F (2, 27, 10) past the critical F-statistic corresponding to our chosen level of significance. We can calculate this formally in R: pf(qf(0.95, 2, 27), 2, 27, ncp = ncp_1, lower.tail = FALSE) ## [1] 0.7673536 4.2 Playing with Sample Size The non-centrality parameter is ultimately what controls the power of our statistical test. The larger the non-centrality parameter, the larger the power. We can deduce from the non-centrality parameter formula that we can change it by: Changing the sample size in our experimental design Changing our treatment group effect sizes Changing our MSE (within treatment group variance) In practice, changing sample size is probably the easiest way to tweak power. The below animation illustrates how the non-centrality parameter and power change with different sample sizes if we keep everything else the same as specified in our above example for calculating power. Figure 4.3: Animation showing the change in power with increasing sample size. The different shades of green represent the changing amounts of power. The graphic adds respective F-distributions and probabilites in order of increasing sample size. The first set of layers correspond to a sample size of 5 replicates per treatment (15 total plots), the next set correspond to 10 per treatment (30 total plots), and the last set correspond to 15 per treatment (45 total plots). Pay attention to the green shaded areas in the graphic, this represents the power in each of our three scenarios with different sample size. The yellow shaded area (non-central F-distribution) widens with increasing sample size leading to higher power! References "],
["check-in-answers.html", "Part 5 Check-in Answers 5.1 Part 2 5.2 Part 3", " Part 5 Check-in Answers 5.1 Part 2 Limiting plots to one insect species is an inclusion criteria imposed on the experiment. The statistical advantage of doing this is you reduce extraneous variation in the response variable due to other factors, which is helpful to reaching a statistically significant result in the ANOVA. The disadvantage of this inclusion criteria is that the scope of the conclusions drawn from the experiment are limited to the chosen insect species. 5.2 Part 3 Scenario 1 will have the larger F-statistic- both scenarios have the same treatment group means and therefore the same amount of between treatment group variation. The two scenarios differ in that scenario 2 has more within group variation. The F-stat is calculated as the ratio between mean square treatment to mean square error leading to a higher F-stat for scenario 1 viz., \\[F^{*} = MS_{trt}/MS_{error}\\] \\[X = \\left[\\begin{array} {rrr} 1 &amp; 1 &amp; 0 \\\\ 1 &amp; 1 &amp; 0\\\\ 1 &amp; 0 &amp; 1\\\\ 1 &amp; 0 &amp; 1\\\\ 1 &amp; -1 &amp; -1\\\\ 1 &amp; -1 &amp; -1\\\\ \\end{array}\\right]\\] "],
["references.html", "References", " References "]
]
